{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#import librosa.display\\nimport setuptools\\n\\nfrom numpy.distutils.core import setup\\n%pylab inline --no-import-all\\n#from scikits.audiolab import wavread\\nfrom scipy import signal\\nimport matplotlib.pyplot as plt\\nfrom scipy.io import wavfile\\nimport math\\nimport numpy as np\\nfrom numpy.fft import fft\\nimport pylab\\n#import mir_eval\\nimport seaborn\\nseaborn.set(style=\"ticks\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load audio file function\n",
    "def loadsingal(filename):\n",
    "    signal ,sample_rate=librosa.load(filename,sr=12000, mono=True)\n",
    "    signal=signal#[int(2.5 * sample_rate):int(3.0 * sample_rate)] \n",
    "    return signal ,sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add silence in the end of audio file \n",
    "def comp_audio(data, fs, T):\n",
    "    # Calculate target number of samples\n",
    "    N_tar = int(fs * T)\n",
    "    # Calculate number of zero samples to append\n",
    "    shape = data.shape\n",
    "    # Create the target shape    \n",
    "    N_pad = N_tar - shape[0]\n",
    "    # print(\"Padding with %s seconds of silence\" % str(N_pad/fs) )\n",
    "    shape = (N_pad,) + shape[1:]\n",
    "    # Stack only if there is something to append    \n",
    "    if shape[0] > 0:                \n",
    "        if len(shape) > 1:\n",
    "            return np.vstack((np.zeros(shape),\n",
    "                              data))\n",
    "        else:\n",
    "            return np.hstack((np.zeros(shape),\n",
    "                              data))\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert audio in spectrogram\n",
    "from scipy import signal\n",
    "def spectrogram(signals,plot=False,sample_rate=12000):\n",
    "    Sxxs=[]\n",
    "    for i,data in enumerate(signals):\n",
    "        f, t, Sxx = signal.spectrogram(data,sample_rate)\n",
    "        Sxxs.append(Sxx)\n",
    "       \n",
    "        if plot==True:\n",
    "            plt.pcolormesh(t, f, Sxx)\n",
    "            plt.ylabel('Frequency [Hz]')\n",
    "            plt.xlabel('Time [sec]')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "    return Sxxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os\n",
    "dir =\"/scratch/mlbd/\"\n",
    "#dir =\"/Users/kimtaing/Documents/github/MLBD/MLBD/birdsong/\"\n",
    "# changes current working directory\n",
    "os.chdir(dir+\"BECASSE_FILTREE\")\n",
    "filenames=[]\n",
    "for file in glob.glob(\"*.wav\"):\n",
    "    filenames.append('/BECASSE_FILTREE/'+file)\n",
    "    \n",
    "# changes current working directory\n",
    "os.chdir(dir+\"NO_BECASSE_FILTREE\")\n",
    "filenames_N=[]\n",
    "for file in glob.glob(\"*.wav\"):\n",
    "    filenames_N.append('NO_BECASSE_FILTREE/'+file)\n",
    "\n",
    "nb_Files=1000\n",
    "filenames=filenames[:nb_Files]\n",
    "filenames_N=filenames_N[:nb_Files]\n",
    "signals=[]\n",
    "signals_N=[]\n",
    "time=float(30)\n",
    "\n",
    "# load becasse audio file\n",
    "for filename in filenames:\n",
    "    path=dir +filename\n",
    "    s ,sample_rate=loadsingal(path)\n",
    "    #complete audio with fonction comp_audio to have commune size\n",
    "    s_t=comp_audio(s,sample_rate,time)\n",
    "    signals.append(s_t)\n",
    "    \n",
    "# load no_becasse audio file\n",
    "for filename in filenames_N:\n",
    "    path=dir +filename\n",
    "    s_N ,sample_rate_N=loadsingal(path)\n",
    "    s_N_t=comp_audio(s_N,sample_rate_N,time)\n",
    "    signals_N.append(s_N_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(dir+\"signals\", 'wb') as f:\n",
    "    pickle.dump(signals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(dir+\"signals_N\", 'wb') as f:\n",
    "    pickle.dump(signals_N, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signals=[]\n",
    "signals_N=[]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
